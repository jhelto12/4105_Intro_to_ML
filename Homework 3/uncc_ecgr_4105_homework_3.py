# -*- coding: utf-8 -*-
"""UNCC ECGR 4105 Homework 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rwV71K6j17V8tbZkk7_QIO-bYsM6zGzq
"""

#https://github.com/jhelto12/4105_Intro_to_ML/tree/main/Homework%203
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from IPython.display import display
from sklearn.model_selection import train_test_split
#from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

from sklearn.datasets import load_breast_cancer
from sklearn.datasets import load_diabetes

url = "https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/main/Dataset/diabetes.csv"
diabetes_df = pd.read_csv(url)

#split the diabetes dataset (input and output)
diabetes_X = diabetes_df.drop('Outcome', axis=1)
diabetes_Y = diabetes_df['Outcome']

#split the diabetes datasets (train and test)
diabetes_X_train, diabetes_X_test, diabetes_Y_train, diabetes_Y_test = train_test_split(diabetes_X, diabetes_Y, test_size=0.2, random_state=42)

#load in the dataset from sklearn library
cancer_data = load_breast_cancer()

#bring in cancer dataset as data and target
cancer_X = cancer_data.data
cancer_y = cancer_data.target

#split the cancer datasets (train and test)
cancer_X_train, cancer_X_test, cancer_Y_train, cancer_Y_test = train_test_split(cancer_X, cancer_y, test_size=0.2, random_state=42)

#create cancer dataframe from dataset
cancer_df = pd.DataFrame(cancer_X_train, columns=cancer_data.feature_names)
cancer_df['target'] = cancer_Y_train

#initialize the scaler function
scaler = StandardScaler()

#scale the diabetes dataframe
diabetes_X_train = scaler.fit_transform(diabetes_X_train)
diabetes_X_test = scaler.transform(diabetes_X_test)

#scale the cancer dataframe
cancer_df[cancer_data.feature_names] = scaler.fit_transform(cancer_df[cancer_data.feature_names])

from sklearn.linear_model import LogisticRegression

# Initialize the logistic regression model
classifier = LogisticRegression(random_state=0)

# Fit the model on the training data
classifier.fit(diabetes_X_train, diabetes_Y_train)

diabetes_predictions = classifier.predict(diabetes_X_test)
diabetes_predictions[0:10]

from sklearn.metrics import confusion_matrix
cfn_matrix_diabetes = confusion_matrix(diabetes_Y_test, diabetes_predictions)
print(cfn_matrix_diabetes)

from sklearn import metrics
print("Accuracy:\t",metrics.accuracy_score(diabetes_Y_test, diabetes_predictions))
print("Precision:\t",metrics.precision_score(diabetes_Y_test, diabetes_predictions))
print("Recall: \t",metrics.recall_score(diabetes_Y_test, diabetes_predictions))
print("F1 Score:\t",metrics.f1_score(diabetes_Y_test, diabetes_predictions))

import seaborn as sns
class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heatmap
sns.heatmap(pd.DataFrame(cfn_matrix_diabetes), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

"""The results of running the logistic regression model on the diabetes dataset leaves a lot to be desired. With only somewhere between a 60% and 70% accuracy, recall, and F1 Score, a lot more can be done for this dataset before the results can be useful."""

# Initialize the logistic regression model
classifier = LogisticRegression(random_state=0)

# Fit the model on the training data
classifier.fit(cancer_df[cancer_data.feature_names], cancer_df['target'])

cancer_predictions = classifier.predict(cancer_df[cancer_data.feature_names])
cancer_predictions[0:10]

cfn_matrix_cancer = confusion_matrix(cancer_df['target'], cancer_predictions)
print(cfn_matrix_cancer)

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions))

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sns.heatmap(pd.DataFrame(cfn_matrix_cancer), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

"""Running the logistic regression model on the Cancer dataset has shown to be significantly more effective at predicting cancer"""

#initialize the logistic regression model with penalties
classifier = LogisticRegression(
    solver='liblinear',
    penalty='l1',
    C=1,
    random_state=0
)

classifier.fit(cancer_df[cancer_data.feature_names], cancer_df['target'])

cancer_predictions_penalties = classifier.predict(cancer_df[cancer_data.feature_names])
cancer_predictions_penalties[0:10]

cfn_matrix_cancer_penalties = confusion_matrix(cancer_df['target'], cancer_predictions_penalties)
print(cfn_matrix_cancer_penalties)

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions_penalties))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions_penalties))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions_penalties))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions_penalties))

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sns.heatmap(pd.DataFrame(cfn_matrix_cancer_penalties), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

"""The results from this section were slightly improved in all four metrics. This seems to indicate that adding in penalties can improve the model."""

from sklearn.naive_bayes import GaussianNB

#initialize the logistic regression model with penalties
classifier = GaussianNB()

classifier.fit(cancer_df[cancer_data.feature_names], cancer_df['target'])

cancer_predictions_gaussian = classifier.predict(cancer_df[cancer_data.feature_names])
cancer_predictions_gaussian[0:10]

cfn_matrix_cancer_gaussian = confusion_matrix(cancer_df['target'], cancer_predictions_gaussian)
print(cfn_matrix_cancer_gaussian)

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions_gaussian))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions_gaussian))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions_gaussian))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions_gaussian))

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sns.heatmap(pd.DataFrame(cfn_matrix_cancer_gaussian), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

"""After using the Gaussian Naive Bias model, results are noticeably worse than the previous tests done with this dataset. The difference in metrics between the Gaussian NB model and the logistic regression model might come down to the fact that the Gaussian NB model runs almost purely on statistical analysis, while the logistic regression is able to use the gradient descent algorithm to more precisely fine tune its parameters."""

from sklearn.decomposition import PCA

pca_components = [1, 2, 5, 6, 7, 8, 9, 10, 20, 30]

for n in pca_components:
  pca = PCA(n_components=n)
  pca.fit(cancer_df[cancer_data.feature_names])
  cancer_df_pca = pca.transform(cancer_df[cancer_data.feature_names])

  explained_variance = pca.explained_variance_ratio_.sum()
  print(f"Number of components: {n}, Cumulative explained variance: {explained_variance:.2f}")

"""Here, I was trying to find a good K value that I could use for the tests. The goal was to find the smallest number of principle components that still met or exceeded 90% variance for the dataset. With that in mind, it looks like the optimal number of principle components might be 7."""

for n in pca_components:
  pca = PCA(n_components=n)
  cancer_X_train_pca = pca.fit_transform(cancer_df[cancer_data.feature_names])
  cancer_X_test_pca = pca.transform(cancer_df[cancer_data.feature_names])

  classifier = GaussianNB()
  classifier.fit(cancer_X_train_pca, cancer_df['target'])

  cancer_predictions_gaussian_pca = classifier.predict(cancer_X_test_pca)
  cfn_matrix_cancer_gaussian_pca = confusion_matrix(cancer_df['target'], cancer_predictions_gaussian_pca)

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions_gaussian_pca))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions_gaussian))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions_gaussian))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions_gaussian))

"""Here is the result of the Gaussian test using after having used the PCA method. There is a noticeable difference between the metrics in this test, but that is to be expected. Some of the data was lost because of the PCA method. This would mean that there is a noticeable, yet not debilitating, in the overall metrics of the test."""

for n in pca_components:
  pca = PCA(n_components=n)
  cancer_X_train_pca = pca.fit_transform(cancer_df[cancer_data.feature_names])
  cancer_X_test_pca = pca.transform(cancer_df[cancer_data.feature_names])

  classifier = LogisticRegression()
  classifier.fit(cancer_X_train_pca, cancer_df['target'])

  cancer_predictions_logistic_pca = classifier.predict(cancer_X_test_pca)
  cfn_matrix_cancer_logistic_pca = confusion_matrix(cancer_df['target'], cancer_predictions_logistic_pca)

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions_logistic_pca))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions_logistic_pca))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions_logistic_pca))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions_logistic_pca))

"""The logistic regression model using the PCA method seems to have done well with its metrics. They are noticeably higher than those of the Gaussian test."""