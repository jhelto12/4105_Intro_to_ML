# -*- coding: utf-8 -*-
"""ECGR 4105 Homework 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YX-h-qm7tiX6BodBpzrnZyYjVqiTqHKW
"""

#https://github.com/jhelto12/4105_Intro_to_ML/tree/main/Homework%204
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from IPython.display import display
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.svm import SVR
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import sklearn.metrics as metrics
from sklearn.datasets import load_breast_cancer

#load in the dataset from sklearn library
cancer_data = load_breast_cancer()

#bring in cancer dataset as data and target
cancer_X = cancer_data.data
cancer_y = cancer_data.target

#split the cancer datasets (train and test)
cancer_X_train, cancer_X_test, cancer_Y_train, cancer_Y_test = train_test_split(cancer_X, cancer_y, test_size=0.2, random_state=42)

#create cancer dataframe from dataset
cancer_df = pd.DataFrame(cancer_X_train, columns=cancer_data.feature_names)
cancer_df['target'] = cancer_Y_train

#initialize the scaler function
scaler = StandardScaler()

#scale the cancer dataframe
cancer_df[cancer_data.feature_names] = scaler.fit_transform(cancer_df[cancer_data.feature_names])

#PCA
from sklearn.decomposition import PCA
pca_components = [1, 2, 5, 6, 7, 8, 9, 10, 20, 30]

for n in pca_components:
  pca = PCA(n_components=n)
  cancer_X_train_pca = pca.fit_transform(cancer_df[cancer_data.feature_names])
  cancer_X_test_pca = pca.transform(cancer_df[cancer_data.feature_names])

  classifier = SVC(kernel='linear')
  classifier.fit(cancer_df[cancer_data.feature_names], cancer_Y_train)

  cancer_predictions = classifier.predict(cancer_df[cancer_data.feature_names])
  cfn_matrix_cancer = confusion_matrix(cancer_df['target'], cancer_predictions)
print(cfn_matrix_cancer)
print(classification_report(cancer_df['target'], cancer_predictions))

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sb.heatmap(pd.DataFrame(cfn_matrix_cancer), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

print('Accuracy:\t',metrics.accuracy_score(cancer_df['target'], cancer_predictions))
print('Precision:\t',metrics.precision_score(cancer_df['target'], cancer_predictions))
print('Recall: \t',metrics.recall_score(cancer_df['target'], cancer_predictions))
print('F1 Score:\t',metrics.f1_score(cancer_df['target'], cancer_predictions))

"""Compared to the basic logisitc regression that was done in homework 3, the results here seem to be considerably better. In the previous homework, all of the metrics were somewhere around the upper 60 percent range, while these are all in the very high 90 percent range."""

svc_linear = SVC(kernel='linear')
svc_linear.fit(cancer_X_train, cancer_Y_train)
svc_linear_predictions = svc_linear.predict(cancer_X_test)
cfn_matrix_svc_linear = confusion_matrix(cancer_Y_test, svc_linear_predictions)
print(cfn_matrix_svc_linear)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sb.heatmap(pd.DataFrame(cfn_matrix_svc_linear), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

print('Accuracy:\t',metrics.accuracy_score(cancer_Y_test, svc_linear_predictions))
print('Precision:\t',metrics.precision_score(cancer_Y_test, svc_linear_predictions))
print('Recall: \t',metrics.recall_score(cancer_Y_test, svc_linear_predictions))
print('F1 Score:\t',metrics.f1_score(cancer_Y_test, svc_linear_predictions))

svc_rbf = SVC(kernel='rbf')
svc_rbf.fit(cancer_X_train, cancer_Y_train)
svc_rbf_predictions = svc_rbf.predict(cancer_X_test)
cfn_matrix_svc_rbf = confusion_matrix(cancer_Y_test, svc_rbf_predictions)
print(cfn_matrix_svc_rbf)

class_names=[0,1]
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

#create heat map
sb.heatmap(pd.DataFrame(cfn_matrix_svc_rbf), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

plt.show()

print('Accuracy:\t',metrics.accuracy_score(cancer_Y_test, svc_rbf_predictions))
print('Precision:\t',metrics.precision_score(cancer_Y_test, svc_rbf_predictions))
print('Recall: \t',metrics.recall_score(cancer_Y_test, svc_rbf_predictions))
print('F1 Score:\t',metrics.f1_score(cancer_Y_test, svc_rbf_predictions))

url = "https://raw.githubusercontent.com/HamedTabkhi/Intro-to-ML/refs/heads/main/Dataset/Housing.csv"
df = pd.read_csv(url)
df.head()

housing_X = df.drop(columns=['price'])
housing_Y = df['price']

#changing string values to appropriate numeric values
binaryColumns = ["mainroad", "guestroom", "basement", "hotwaterheating", "airconditioning", "prefarea"]
def binaryMap(x):
  return x.map({'yes': 1, 'no': 0})

housing_X['furnishingstatus'] = housing_X['furnishingstatus'].replace({
    'furnished': 3,
    'semi-furnished': 2,
    'unfurnished': 1
})

housing_X[binaryColumns] = housing_X[binaryColumns].apply(binaryMap)
housing_X.head()

housing_X_train, housing_X_test, housing_Y_train, housing_Y_test = train_test_split(housing_X, housing_Y, test_size=0.2, random_state=42)

pca_components = [1, 2, 5, 6, 7, 8, 9, 10, 12]
for n in pca_components:
  pca = PCA(n_components=n)
  housing_X_train_pca = pca.fit_transform(housing_X_train)
  housing_X_test_pca = pca.transform(housing_X_test)

  regressor = SVR(kernel='linear',)
  regressor.fit(housing_X_train_pca, housing_Y_train)

  housing_predictions = regressor.predict(housing_X_test_pca)

#plot the training error
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(regressor.support_vectors_) + 1), regressor.support_
         / regressor.support_.sum() *
         100, 'o-', linewidth=2, color='red')
plt.xticks(range(1, len(regressor.support_vectors_) + 1))
plt.xlabel('Support vector index')
plt.ylabel('Relative size')
plt.show()

#plot the testing error
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(regressor.support_vectors_) + 1), regressor.support_
         / regressor.support_.sum() *
         100, 'o-', linewidth=2, color='red')
plt.xticks(range(1, len(regressor.support_vectors_) + 1))
plt.xlabel('Support vector index')
plt.ylabel('Relative size')
plt.show()